{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versjon 08.01.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduksjon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denne notebooken er ment som en relativt enkel illustrasjon av analyse av sensordata med maskinlæring. Se slides fra introduksjonen for motivasjon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from pathlib import Path\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi bruker et sensor-datasett fra UCI Machine Learning, tilgjenglig via Kaggle: https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones. Fra 30 personer ble det samlet målinger fra en smart-telefon mens de utførte dagligdagse oppgaver. Vår oppgave er å predikere hvilken oppgave som ble utført direkte fra sensor-målingene. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video som beskriver innsamlingen av data: https://www.youtube.com/watch?v=XOEN9W05_4A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"https://www.youtube.com/embed/XOEN9W05_4A\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x24c5093c808>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.IFrame(width=\"560\", height=\"315\", src=\"https://www.youtube.com/embed/XOEN9W05_4A\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her er en beskrivelse av datasettet, sakset fra Kaggle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Human Activity Recognition database was built from the recordings of 30 study participants performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors. The objective is to classify activities into one of the six activities performed.\n",
    "\n",
    "> **Description of experiment**<br>\n",
    "The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where **70% of the volunteers was selected for generating the training data and 30% the test data**.\n",
    "\n",
    "> The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.\n",
    "\n",
    "> **Attribute information**<br>\n",
    "> For each record in the dataset the following is provided:\n",
    "\n",
    "> * Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.\n",
    "* Triaxial Angular velocity from the gyroscope.\n",
    "* A 561-feature vector with time and frequency domain variables.\n",
    "* Its activity label.\n",
    "* An identifier of the subject who carried out the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Last inn og utforsk data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Vi har allerede hentet data fra Kaggle. Plassert i katalogen `../data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DATA = Path('../data/sensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA/'train.csv')\n",
    "test = pd.read_csv(DATA/'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Vi har fått to dataframes bestående av en lang rekke sensormålinger, markert med tilhørende aktiviteter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Vi ser at det er 7352 treningsdata og 2947 testdata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Hvordan ser data ut? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For å vise alle søylene i data frames:\n",
    "pd.set_option('display.max_columns', 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Her er noen labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.random.choice(train['Activity'], size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "De seks ulike aktivitetene vi skal detektere er:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.unique(train['Activity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fordelingen av disse i treningsdata er:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train['Activity'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Ekstra: korrelasjoner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Det er helt sikkert stor korrelasjon mellom mange av features i dette datasettet (akselerasjon og gyroskop-features, for eksempel). Vi kan avdekke dette ved å bruke korrelasjonsmatrisen, og så trekke ut egenskapene som er mest korrelert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix = train.corr()\n",
    "correlation_matrix.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Korrelasjonsmatrisen er en 562x562-matrise (alle numeriske features korrelert med alle numeriske features). Her er de føste 10 søyler og 10 rader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix.iloc[0:10, 0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Vi ønsker å plukke ut parene av features som har høyest korrelasjon. Vi kan gjøre dette med `unstack`, som gjør alle verdiene i søylen helt til venstre (index-søylen) til søyler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix.unstack().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix.unstack()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Vi får altså 315844 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "562*562"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nå kan vi plukke ut de 15 minste og største tallene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix.unstack().drop_duplicates().sort_values()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correlation_matrix.unstack().drop_duplicates().sort_values()[-15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Som vi trodde: det er mange features som er veldig høyt korrelert. \n",
    "\n",
    "> En kan (ofte med fordel) fjerne features som er veldig høyt korrelert fra data. Det kan øke ytelsen til modellene. Forsøk gjerne dette her!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Splitt opp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Vi deler opp data i input X og output y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop('Activity', axis=1)\n",
    "y_train = train['Activity']\n",
    "\n",
    "X_test = test.drop('Activity', axis=1)\n",
    "y_test = test['Activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Vi bruker vår venn `RandomForestClassifier`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Senere skal du få vite nøyaktig hvordan denne fungerer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Hvor bra accuracy får vi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Over 92%! \n",
    "\n",
    "Er dette bra? For å svare på det må vi bruke verktøyene vi har lært om for evaluering av klassifikatorer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluer resultatet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Forvirringsmatrise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils import plot_confusion_matrix, plot_confusion_matrix_with_colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix_with_colorbar(cm, classes=np.unique(y_test), figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Her er de 10 features som ble vektet høyest av vår modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "# Find index of those with highest importance, sorted from largest to smallest:\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(10): \n",
    "    print(f'{X_test.columns[indices[f]]}: {np.round(importances[indices[f]],2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Permutation importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Som kjent er feature importance for random forests en veldig ustabil og lite gunstig måte å måle faktisk viktighet av features (ta en titt tilbake på Lab 0 for mer om dette). Permutation importance gir mer stabile, data-drevne estimat av feature importance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Advarsel:** dette tar litt tid siden vi har såpass mange features-søyler som skal shuffles..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#?PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm = PermutationImportance(rf, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perm.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Resultat:**\n",
    "\n",
    "<img width=30% src=\"assets/permimportance_sensor.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fin-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Som diskutert i notebooken fra Lab 1 er det en rekke ting en kan gjøre dersom en ikke er fornøyd med ytelsen til en maskinlæringsmodell. En av disse er å justere på såkalte **hyperparametre** i modellen (dvs parametre som ikke settes under trening, men velges av oss). \n",
    "\n",
    "Som vi skal se senere (når vi kommer til hvordan random forests fungerer) er det en rekke hyperparametre i random forests som kan influere ytelsen. \n",
    "\n",
    "En mye brukt strategi for å finne gode valg av parametre er å *søke* gjennom et bestemt *grid* av potensielle parameterkombinasjoner. Enten ved å forsøke alle (dette kalles **grid search**) eller ved å forsøke et tilfeldig antall valg (dette kalles **randomized search**). Det finnes også andre, mer avanserte former for *hyperparameteroptimalisering*, for eksempel **bayesian search**. Vi skal se på grid search og randomized search. For bayesiansk søk, se for eksempel `scikit-optimize`: https://scikit-optimize.github.io/#skopt.BayesSearchCV.  \n",
    "\n",
    "(Det er også mulig å søke gjennom ulike *modeller* i tillegg til deres hyperparemetre, men det skal vi ikke gå inn på her)\n",
    "\n",
    "Vi forsøker:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Et mulig parametergrid å søke gjennom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Her er to parametergrid som ofte vil fungere bra for random forest. Nøyaktig hvilke parametre som gir mening å forsøke i en gitt situasjon avhenger blant annet av datasettet en har. For å velge klokt her kreves det en del erfaring, samt forståelse av modellen. \n",
    "\n",
    "La oss bare velge noe relativt trygt, og så ikke bry oss om dette er det *beste* valget.\n",
    "\n",
    "Vi lager to grids, et lite; et stort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_grid_small = {\n",
    "    \n",
    "    'max_depth': [5, 10, 15, 20, 30, 100, None],\n",
    "    'n_estimators': [50, 100, 500, 1000]\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "param_grid_large = {\n",
    "     'bootstrap': [True, False],\n",
    "     'max_depth': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "     'min_samples_leaf': [1, 2, 4],\n",
    "     'min_samples_split': [2, 5, 10],\n",
    "     'n_estimators': [50, 100, 500, 1000]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Når vi senere kjører grid search, randomized search og bayesian search, blir disse grids konvertert til en type matriser, og alle kombinasjoner av parametre blir potensielle kandidater. \n",
    "\n",
    "Det betyr 7x4 = 28 kombinasjoner for `param_grid_small` og 2x12x3x3x4 = 864 kombinasjoner for `param_grid_large`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Å søke gjennom absolutt alle kombinasjoner i `param_grid_large` blir for kostbart tidsmessig. Vi bruker derfor `param_grid_small`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_gs = GridSearchCV(estimator=rf, param_grid=param_grid_small, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_gs_model = rf_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_gs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Søket klarte i dette tilfellet ikke å finne en bedre parameterkombinasjon enn den vi allerede hadde. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Randomized search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Med randomized search er de vi som bestemmer antall (tilfeldig valgte) kombinasjoner som skal forsøkes. Vi kan derfor tillate oss å bruke `param_grid_large`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_rs = RandomizedSearchCV(estimator=rf, param_distributions=param_grid_large, n_iter=50, cv=3, n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_rs_model = rf_rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_rs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_rs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Fortsatt ikke vesentlig bedre enn vår første modell. \n",
    "\n",
    "Med et større søk (det vil si, `n_iter` satt til et større tall) kan det hende at vi oppdager bedre parametre. Men jo større antall forsøk, jo lenger beregningstid..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Noen oppgaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> **Din tur!** Klarer du å lage en modell som kan predikere hvilken person som genererte hver sensormåling? <em>Gi meg din mobiltelefon så skal jeg fortelle deg hvem du er</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> **Din tur!** Undersøk hvilke bevegelser som best skiller personer fra hverandre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Ekstra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La oss forsøke en annen modell: **logistisk regresjon**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "std_sc = StandardScaler()\n",
    "X_train_std = std_sc.fit_transform(X_train)\n",
    "X_test_std = std_sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, C=0.2, random_state=42)\n",
    "log_reg.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_reg.score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Denne modellen scorer 96%, altså langt bedre enn de random forest-variantene vi forsøkte over. Dette illusterer viktigheten av hensiktsmessig modellvalg, tilpasset data og problemstilling man står ovenfor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Forvirringsmatrise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_logreg = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
    "\n",
    "plot_confusion_matrix_with_colorbar(cm_logreg, classes=np.unique(y_test), figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Denne kan sammenlignes fra vår forvirringsmatrise fra random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix_with_colorbar(cm, classes=np.unique(y_test), figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Ekstra ekstra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For moro skyld, la oss også forsøke noe kraftigere: en gradient boosting-basert modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state=42, n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ca. 94%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Forvirringsmatrise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_gs = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm_gs = confusion_matrix(y_test, y_pred_gs)\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "_ = plot_confusion_matrix(cm_gs, classes=np.unique(y_test), ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "En (av mange) mulige måter å forbedre modeller på er å bruke **ensembling**: slå sammen prediksjonene fra flere modeller. Dette er spesielt nyttig dersom man har flere, svært ulike modeller, som hver for seg scorer høyt. Sammen kan de da ofte bli enda bedre (*wisdom of the crowd*).\n",
    "\n",
    "La oss forsøke med de vi har til nå:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('rf', best_rs_model), ('logreg', log_reg), ('gnb', gb)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eclf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I vårt tilfelle gav ikke dette en bedre modell enn logistisk regresjon alene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_eclf = eclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cm_eclf = confusion_matrix(y_test, y_pred_eclf)\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "_ = plot_confusion_matrix(cm_eclf, classes=np.unique(y_test), ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Merk: For å slippe å trene modellene på nytt når de ensembles kunne vi brukt mlextend \n",
    "# sin EnsembleVoteClassifier. Det vil spare mye tid:\n",
    "\n",
    "#!pip install mlextend\n",
    "#from mlxtend.classifier import EnsembleVoteClassifier\n",
    "#import copy\n",
    "#eclf = EnsembleVoteClassifier(clfs=[best_rs_model, gnb], weights=[1,1], refit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELMED219",
   "language": "python",
   "name": "elmed219"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
